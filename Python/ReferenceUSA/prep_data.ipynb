{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10000001\n",
      "20000001\n",
      "30000001\n",
      "40000001\n",
      "50000001\n",
      "60000001\n",
      "70000001\n",
      "80000001\n",
      "90000001\n",
      "100000001\n",
      "110000001\n",
      "120000001\n",
      "130000001\n",
      "140000001\n",
      "150000001\n",
      "160000001\n",
      "170000001\n",
      "180000001\n",
      "190000001\n",
      "200000001\n",
      "210000001\n",
      "220000001\n",
      "230000001\n",
      "240000001\n",
      "250000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, errno\n",
    "\n",
    "def silentremove(filename):\n",
    "   try:\n",
    "       os.remove(filename)\n",
    "   except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
    "       if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
    "           raise # re-raise exception if a different error occurred\n",
    "\n",
    "# Create a relative path to the base directory\n",
    "base = '../'\n",
    "\n",
    "group_map = dict(\n",
    "    main = ['Company', 'ABI', 'archive_version_year'],\n",
    "    geo = ['City', 'State', 'ZipCode', 'County_Code',\n",
    "          'CBSA_Code'],\n",
    "    industry = ['Primary_SIC_Code', 'Primary_NAICS_Code',\n",
    "               'SIC_Code', 'SIC_Code_1', 'SIC_Code_2'],\n",
    "    structure = ['Business_Status_Code', 'Company_Holding_Status',\n",
    "                'Subsidiary_Number', 'Parent_Number', 'IDCode'],\n",
    "    descript = ['year_established', 'employee_size_location', 'sales_volume_location']\n",
    ")\n",
    "\n",
    "col_types = {'Company':object,  \n",
    "             'City': object,\n",
    "             'State': object,\n",
    "             'ZipCode': np.float64,\n",
    "             'County_Code': np.float64,\n",
    "             'IDCode': np.float64,\n",
    "             'Primary_SIC_Code': np.float64,\n",
    "             'SIC_Code': np.float64,\n",
    "             'SIC_Code_1': np.float64,\n",
    "             'SIC_Code_2': np.float64,\n",
    "             'Primary_NAICS_Code': np.float64,\n",
    "             'Business_Status_Code': np.float64,\n",
    "             'Company_Holding_Status': np.float64,\n",
    "             'ABI': np.int32,\n",
    "             'Parent_Number':np.float64,\n",
    "             'Subsidiary_Number':np.float64,\n",
    "             'CBSA_Code': np.float64,\n",
    "             'archive_version_year': np.int16,\n",
    "             'year_established': np.float64,\n",
    "             'employee_size_location':np.float64,\n",
    "             'sales_colume_location': np.float64}\n",
    "\n",
    "# Create a filename where we can store all records in an HDF5 file\n",
    "filename = base + 'Data/ReferenceUSA/sample.h5'\n",
    "# Clear the HdF5 file so we're not doubling up the data\n",
    "silentremove(filename)\n",
    "# Attach to the HDF5 file\n",
    "store = pd.HDFStore(filename)\n",
    "\n",
    "for obs_num in range(1,260000001,10000000):\n",
    "    print(obs_num)\n",
    "    # Set the file path to read in the CSV data\n",
    "    raw_data = base + 'Data/ReferenceUSA/sample_cond_' + str(obs_num) +'.csv'\n",
    "    # Read in the ReferenceUSA data from CSV\n",
    "    data = pd.read_csv(raw_data, dtype=col_types)\n",
    "    # Only keep data after 2012, since stripe data only starts sin 2013\n",
    "    data = data[data.archive_version_year>=2013]\n",
    "    # Fix the Parent_Number Column so that it's a float, and not a string\n",
    "    #data['Parent_Number'] = data.Parent_Number.astype('float64')\n",
    "    # Append the data to an HDF5 file for easier storage\n",
    "    \n",
    "    try:\n",
    "        nrows = store.get_storer('main').nrows\n",
    "    except:\n",
    "        nrows = 0\n",
    "    \n",
    "    data.index = pd.Series(data.index) + nrows\n",
    "    \n",
    "    for name, fields in group_map.items():\n",
    "        store.append(name, data[fields], dropna=False, expectedrows = 47500177)\n",
    "                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
